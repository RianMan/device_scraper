#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVå·¥å…·æ¨¡å— - tools/csv_tools.py
è´Ÿè´£CSVæ–‡ä»¶çš„è¯»å–å’Œå†™å…¥æ“ä½œ
"""

import pandas as pd
import os
import logging
from datetime import datetime
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

class CSVTools:
    """CSVæ“ä½œå·¥å…·ç±»"""
    
    @staticmethod
    def read_model_codes_csv(csv_file="model_codes.csv"):
        """è¯»å–model_codes.csvæ–‡ä»¶"""
        try:
            if not os.path.exists(csv_file):
                logger.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return []
            
            df = pd.read_csv(csv_file)
            logger.info(f"è¯»å–CSVæ–‡ä»¶: {csv_file}, å…± {len(df)} è¡Œ")
            
            # è·å–å”¯ä¸€çš„å‹å·ä»£ç 
            if 'model_code' in df.columns:
                unique_models = df['model_code'].dropna().unique()
            else:
                logger.error(f"CSVæ–‡ä»¶ç¼ºå°‘ 'model_code' åˆ—")
                return []
            
            logger.info(f"å”¯ä¸€å‹å·æ•°é‡: {len(unique_models)}")
            
            # è½¬æ¢ä¸ºå¤„ç†æ ¼å¼
            devices = []
            for model_code in unique_models:
                if pd.notna(model_code) and str(model_code).strip():
                    devices.append({
                        'model_code': str(model_code).strip()
                    })
            
            logger.info(f"æœ‰æ•ˆè®¾å¤‡æ•°é‡: {len(devices)}")
            return devices
            
        except Exception as e:
            logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    @staticmethod
    def read_device_result_csv(csv_file="device_result.csv"):
        """è¯»å–device_result.csvæ–‡ä»¶ï¼ˆåŒ…å«manufactureå’Œmodelåˆ—ï¼‰"""
        try:
            if not os.path.exists(csv_file):
                logger.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return []
            
            df = pd.read_csv(csv_file)
            logger.info(f"è¯»å–CSVæ–‡ä»¶: {csv_file}, å…± {len(df)} è¡Œ")
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_columns = ['clientmanufacture', 'clientmodel']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                logger.error(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                return []
            
            # æå–è®¾å¤‡ä¿¡æ¯
            devices = []
            for index, row in df.iterrows():
                manufacture = str(row['clientmanufacture']).strip() if pd.notna(row['clientmanufacture']) else ''
                model = str(row['clientmodel']).strip() if pd.notna(row['clientmodel']) else ''
                
                if manufacture and model:
                    devices.append({
                        'manufacture': manufacture,
                        'model_code': model,
                        'raw_data': f"{manufacture} {model}"
                    })
            
            logger.info(f"æå–åˆ° {len(devices)} ä¸ªæœ‰æ•ˆè®¾å¤‡ä¿¡æ¯")
            return devices
            
        except Exception as e:
            logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    @staticmethod
    def save_device_results(results: List[Dict[str, Any]], filename_prefix="device_info_extracted"):
        """ä¿å­˜è®¾å¤‡ä¿¡æ¯ç»“æœåˆ°CSV"""
        try:
            if not results:
                logger.warning("æ²¡æœ‰ç»“æœéœ€è¦ä¿å­˜")
                return None
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{filename_prefix}_{timestamp}.csv"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = "output"
            os.makedirs(output_dir, exist_ok=True)
            filepath = os.path.join(output_dir, filename)
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(results)
            
            # ä¿å­˜åˆ°CSV
            df.to_csv(filepath, index=False, encoding='utf-8')
            
            logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(results)} æ¡ç»“æœåˆ°: {filepath}")
            
            # æ˜¾ç¤ºæ ·ä¾‹æ•°æ®
            if len(results) > 0:
                sample = results[0]
                logger.info(f"ğŸ“‹ æ ·ä¾‹æ•°æ®:")
                logger.info(f"   è®¾å¤‡: {sample.get('device_name', 'N/A')}")
                logger.info(f"   ä»·æ ¼: {sample.get('price', 'N/A')}")
                logger.info(f"   å‘å¸ƒ: {sample.get('announced_date', 'N/A')}")
            
            return filepath
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
            return None
    
    @staticmethod
    def save_failed_devices(failed_devices: List[Dict[str, Any]], filename_prefix="failed_devices"):
        """ä¿å­˜å¤±è´¥çš„è®¾å¤‡ä¿¡æ¯"""
        try:
            if not failed_devices:
                logger.info("æ²¡æœ‰å¤±è´¥çš„è®¾å¤‡éœ€è¦ä¿å­˜")
                return None
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{filename_prefix}_{timestamp}.csv"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = "output"
            os.makedirs(output_dir, exist_ok=True)
            filepath = os.path.join(output_dir, filename)
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(failed_devices)
            
            # ä¿å­˜åˆ°CSV
            df.to_csv(filepath, index=False, encoding='utf-8')
            
            logger.info(f"âŒ å¤±è´¥è®¾å¤‡å·²ä¿å­˜åˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥è®¾å¤‡å¤±è´¥: {str(e)}")
            return None
    
    @staticmethod
    def save_processing_log(log_data: Dict[str, Any], filename_prefix="processing_log"):
        """ä¿å­˜å¤„ç†æ—¥å¿—"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{filename_prefix}_{timestamp}.csv"
            
            output_dir = "output"
            os.makedirs(output_dir, exist_ok=True)
            filepath = os.path.join(output_dir, filename)
            
            # åˆ›å»ºæ—¥å¿—è®°å½•
            log_record = [{
                'timestamp': timestamp,
                'total_devices': log_data.get('total_devices', 0),
                'successful_devices': log_data.get('successful_devices', 0),
                'failed_devices': log_data.get('failed_devices', 0),
                'success_rate': log_data.get('success_rate', 0),
                'processing_time_seconds': log_data.get('processing_time_seconds', 0),
                'google_searches': log_data.get('google_searches', 0),
                'gsmarena_direct_hits': log_data.get('gsmarena_direct_hits', 0),
                'gsmchoice_fallbacks': log_data.get('gsmchoice_fallbacks', 0),
                'notes': log_data.get('notes', '')
            }]
            
            df = pd.DataFrame(log_record)
            df.to_csv(filepath, index=False, encoding='utf-8')
            
            logger.info(f"ğŸ“Š å¤„ç†æ—¥å¿—å·²ä¿å­˜åˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"ä¿å­˜å¤„ç†æ—¥å¿—å¤±è´¥: {str(e)}")
            return None
    
    @staticmethod
    def create_sample_model_codes_csv(filename="model_codes.csv", sample_count=5):
        """åˆ›å»ºç¤ºä¾‹model_codes.csvæ–‡ä»¶ç”¨äºæµ‹è¯•"""
        try:
            sample_models = [
                "SM-J415G",
                "moto g(50) 5G", 
                "ZTE 8050",
                "CPH2387",
                "LM-X420"
            ]
            
            # å¦‚æœè¯·æ±‚æ›´å¤šæ ·æœ¬ï¼Œé‡å¤åˆ—è¡¨
            if sample_count > len(sample_models):
                multiplier = (sample_count // len(sample_models)) + 1
                extended_models = (sample_models * multiplier)[:sample_count]
            else:
                extended_models = sample_models[:sample_count]
            
            df = pd.DataFrame({'model_code': extended_models})
            df.to_csv(filename, index=False)
            
            logger.info(f"âœ… åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶: {filename}, åŒ…å« {len(extended_models)} ä¸ªå‹å·")
            return filename
            
        except Exception as e:
            logger.error(f"åˆ›å»ºç¤ºä¾‹CSVå¤±è´¥: {str(e)}")
            return None
    
    @staticmethod
    def validate_csv_structure(csv_file, required_columns):
        """éªŒè¯CSVæ–‡ä»¶ç»“æ„"""
        try:
            if not os.path.exists(csv_file):
                return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}"
            
            df = pd.read_csv(csv_file)
            
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                return False, f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}"
            
            if len(df) == 0:
                return False, "æ–‡ä»¶ä¸ºç©º"
            
            return True, f"æ–‡ä»¶æœ‰æ•ˆï¼ŒåŒ…å« {len(df)} è¡Œæ•°æ®"
            
        except Exception as e:
            return False, f"æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}"
    
    @staticmethod
    def merge_results_files(file_pattern="output/device_info_extracted_*.csv", output_filename="merged_results.csv"):
        """åˆå¹¶å¤šä¸ªç»“æœæ–‡ä»¶"""
        try:
            import glob
            
            files = glob.glob(file_pattern)
            if not files:
                logger.warning(f"æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶: {file_pattern}")
                return None
            
            logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶è¿›è¡Œåˆå¹¶")
            
            all_dfs = []
            for file in files:
                try:
                    df = pd.read_csv(file)
                    df['source_file'] = os.path.basename(file)
                    all_dfs.append(df)
                    logger.info(f"è¯»å–æ–‡ä»¶: {file} ({len(df)} è¡Œ)")
                except Exception as e:
                    logger.warning(f"è·³è¿‡æ–‡ä»¶ {file}: {str(e)}")
            
            if not all_dfs:
                logger.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶")
                return None
            
            # åˆå¹¶æ‰€æœ‰DataFrame
            merged_df = pd.concat(all_dfs, ignore_index=True)
            
            # å»é‡ï¼ˆåŸºäºmodel_codeï¼‰
            initial_count = len(merged_df)
            merged_df = merged_df.drop_duplicates(subset=['original_model_code'], keep='last')
            final_count = len(merged_df)
            
            # ä¿å­˜åˆå¹¶ç»“æœ
            output_dir = "output"
            os.makedirs(output_dir, exist_ok=True)
            output_path = os.path.join(output_dir, output_filename)
            
            merged_df.to_csv(output_path, index=False, encoding='utf-8')
            
            logger.info(f"âœ… åˆå¹¶å®Œæˆ: {output_path}")
            logger.info(f"ğŸ“Š åˆå¹¶å‰: {initial_count} è¡Œï¼Œå»é‡å: {final_count} è¡Œ")
            
            return output_path
            
        except Exception as e:
            logger.error(f"åˆå¹¶æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None