#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GSMChoiceçˆ¬è™«æ¨¡å— - gsmchoice/gsmchoice_scraper.py
è´Ÿè´£ä»GSMChoiceç½‘ç«™è·å–è®¾å¤‡åç§°
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import random
import logging
from urllib.parse import quote_plus, urljoin
import re

logger = logging.getLogger(__name__)

class GSMChoiceScraper:
    def __init__(self, request_delay=2):
        """åˆå§‹åŒ–GSMChoiceçˆ¬è™«"""
        self.base_url = "https://www.gsmchoice.com"
        self.search_api = "https://www.gsmchoice.com/js/searchy.xhtml"
        self.request_delay = request_delay
        self.session = requests.Session()
        
        # éšæœºUser-Agentæ± 
        self.user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        ]
        
        self._update_session_headers()
    
    def _get_random_user_agent(self):
        return random.choice(self.user_agents)
    
    def _update_session_headers(self):
        self.session.headers.update({
            'User-Agent': self._get_random_user_agent(),
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://www.gsmchoice.com/en/',
            'X-Requested-With': 'XMLHttpRequest'
        })
    
    def _random_delay(self):
        delay = random.uniform(self.request_delay * 0.8, self.request_delay * 1.5)
        time.sleep(delay)
    
    def search_device_name(self, model_code, brand_hint=None):
        """æœç´¢è®¾å¤‡åç§°å’Œå‘å¸ƒæ—¥æœŸ"""
        try:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_query = model_code
            
            logger.info(f"ğŸ” GSMChoiceæœç´¢è®¾å¤‡ä¿¡æ¯: {search_query}")
            
            # æ–¹æ³•1: APIæœç´¢
            api_result = self._search_via_api(search_query)
            if api_result:
                # APIæœç´¢æˆåŠŸï¼Œä½†åªæœ‰è®¾å¤‡åç§°ï¼Œéœ€è¦è·å–è¯¦ç»†ä¿¡æ¯
                device_info = self._get_device_details_by_name(api_result)
                if device_info:
                    return {
                        'success': True,
                        'device_name': device_info['name'],
                        'announced_date': device_info.get('announced_date', ''),
                        'source': 'gsmchoice_api'
                    }
            
            # æ–¹æ³•2: ç½‘é¡µæœç´¢
            web_result = self._search_via_web(search_query)
            if web_result:
                return {
                    'success': True,
                    'device_name': web_result['name'],
                    'announced_date': web_result.get('announced_date', ''),
                    'source': 'gsmchoice_web'
                }
            
            logger.warning(f"âŒ GSMChoiceæœªæ‰¾åˆ°è®¾å¤‡: {model_code}")
            return {
                'success': False,
                'message': f'æœªæ‰¾åˆ°è®¾å¤‡: {model_code}'
            }
            
        except Exception as e:
            logger.error(f"GSMChoiceæœç´¢å¤±è´¥ {model_code}: {str(e)}")
            return {
                'success': False,
                'message': f'æœç´¢å¤±è´¥: {str(e)}'
            }
    
    def _get_device_details_by_name(self, device_name):
        """é€šè¿‡è®¾å¤‡åç§°è·å–è¯¦ç»†ä¿¡æ¯"""
        try:
            # encoded_name = quote_plus(device_name)
            # search_url = f"{self.base_url}/en/search/?sSearch4={encoded_name}"
            search_url = f"{self.base_url}/en/catalogue/{device_name}/"
            return self._extract_device_name_from_page(search_url)
            # print(search_url, "search_urlsearch_url")
            # self._random_delay()
            
            # response = self.session.get(search_url, timeout=30)
            # response.raise_for_status()
            
            # soup = BeautifulSoup(response.content, 'html.parser')
            
            # # æŸ¥æ‰¾è®¾å¤‡é“¾æ¥
            # device_links = soup.find_all('a', href=re.compile(r'/en/catalogue/.*\.php'))
            
            # if device_links:
            #     first_link = device_links[0]
            #     detail_url = urljoin(self.base_url, first_link.get('href', ''))
                
            #     return self._extract_device_name_from_page(detail_url)
            
            # return None
            
        except Exception as e:
            logger.warning(f"è·å–è®¾å¤‡è¯¦æƒ…å¤±è´¥: {str(e)}")
            return None
    
    def _search_via_api(self, search_query):
        """é€šè¿‡APIæœç´¢è®¾å¤‡"""
        try:
            encoded_query = quote_plus(search_query)
            search_url = f"{self.search_api}?search={encoded_query}&lang=en&v=3"
            
            self._random_delay()
            
            response = self.session.get(search_url, timeout=30)
            
            response.raise_for_status()
            
            try:
                results = response.json()
            except json.JSONDecodeError:
                logger.warning(f"GSMChoice APIè¿”å›éJSONå“åº”: {search_query}")
                return None
            
            if not results or len(results) == 0:
                logger.warning(f"GSMChoice APIæ— æœç´¢ç»“æœ: {search_query}")
                return None
            
            # å–ç¬¬ä¸€ä¸ªç»“æœçš„è®¾å¤‡åç§°
            first_result = results[0]
            # device_name = first_result.get('model', '').strip()
            smodel = first_result.get('smodel', '').strip()
            sbrand = first_result.get('sbrand', '').strip()
            device_name = sbrand + '/' + smodel
            if device_name and device_name != 'Unknown':
                logger.info(f"âœ… GSMChoice APIæ‰¾åˆ°è®¾å¤‡: {device_name}")
                return device_name
            
            return None
            
        except Exception as e:
            logger.warning(f"GSMChoice APIæœç´¢å¤±è´¥: {str(e)}")
            return None
    
    def _search_via_web(self, search_query):
        """é€šè¿‡ç½‘é¡µæœç´¢è®¾å¤‡"""
        try:
            encoded_query = quote_plus(search_query)
            search_url = f"{self.base_url}/en/search/?sSearch4={encoded_query}"
            
            self._random_delay()
            
            response = self.session.get(search_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æŸ¥æ‰¾è®¾å¤‡é“¾æ¥
            device_links = soup.find_all('a', href=re.compile(r'/en/catalogue/.*\.php'))
            
            if not device_links:
                logger.warning(f"GSMChoiceç½‘é¡µæœç´¢æ— ç»“æœ: {search_query}")
                return None
            
            # è®¿é—®ç¬¬ä¸€ä¸ªè®¾å¤‡é¡µé¢è·å–å®Œæ•´ä¿¡æ¯
            first_link = device_links[0]
            detail_url = urljoin(self.base_url, first_link.get('href', ''))
            
            device_info = self._extract_device_name_from_page(detail_url)
            
            if device_info and device_info['name']:
                logger.info(f"âœ… GSMChoiceç½‘é¡µæ‰¾åˆ°è®¾å¤‡: {device_info['name']}")
                return device_info
            
            return None
            
        except Exception as e:
            logger.warning(f"GSMChoiceç½‘é¡µæœç´¢å¤±è´¥: {str(e)}")
            return None
    
    def _extract_device_name_from_page(self, detail_url):
        """ä»è®¾å¤‡è¯¦æƒ…é¡µæå–è®¾å¤‡åç§°å’Œå‘å¸ƒæ—¥æœŸ"""
        try:
            self._random_delay()
            
            response = self.session.get(detail_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            device_info = {
                'name': None,
                'announced_date': None
            }
            
            # æŸ¥æ‰¾è®¾å¤‡åç§° - ä¼˜å…ˆä½¿ç”¨PhoneModelName divä¸­çš„infoline__title
            phone_model_div = soup.find('div', {'id': 'PhoneModelName'})
            if phone_model_div:
                title_element = phone_model_div.find('h1', class_='infoline__title')
                if title_element:
                    title_span = title_element.find('span')
                    if title_span:
                        device_name = title_span.get_text(strip=True)
                        if device_name:
                            device_info['name'] = device_name
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾é¡µé¢titleæ ‡ç­¾
            if not device_info['name']:
                title_tag = soup.find('title')
                if title_tag:
                    title_text = title_tag.get_text(strip=True)
                    if title_text:
                        device_name = title_text.split(' - ')[0].split(' | ')[0]
                        device_info['name'] = device_name.strip()
            
            # æå–å‘å¸ƒæ—¥æœŸ
            announced_date = self._extract_announced_date(soup)
            if announced_date:
                device_info['announced_date'] = announced_date
            
            return device_info
            
        except Exception as e:
            logger.warning(f"æå–è®¾å¤‡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def _extract_announced_date(self, soup):
        """ä»GSMChoiceé¡µé¢æå–å‘å¸ƒæ—¥æœŸ"""
        try:
            # æŸ¥æ‰¾è§„æ ¼è¡¨æ ¼ä¸­çš„Announcedå­—æ®µ
            spec_table = soup.find('table', class_='PhoneData')
            if spec_table:
                rows = spec_table.find_all('tr')
                for row in rows:
                    th = row.find('th', class_='phoneCategoryName')
                    td = row.find('td', class_='phoneCategoryValue')
                    
                    if th and td:
                        key = th.get_text(strip=True)
                        if 'Announced' in key:
                            value_span = td.find('span')
                            if value_span:
                                announced_date = value_span.get_text(strip=True)
                                logger.info(f"âœ… GSMChoiceæ‰¾åˆ°å‘å¸ƒæ—¥æœŸ: {announced_date}")
                                return announced_date
            
            return None
            
        except Exception as e:
            logger.warning(f"æå–å‘å¸ƒæ—¥æœŸå¤±è´¥: {str(e)}")
            return None
    
    def get_device_specifications(self, device_name):
        """è·å–è®¾å¤‡è§„æ ¼ä¿¡æ¯ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            logger.info(f"ğŸ” è·å–GSMChoiceè®¾å¤‡è§„æ ¼: {device_name}")
            
            # é€šè¿‡è®¾å¤‡åç§°æœç´¢
            encoded_name = quote_plus(device_name)
            search_url = f"{self.base_url}/en/search/?sSearch4={encoded_name}"
            
            self._random_delay()
            
            response = self.session.get(search_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æŸ¥æ‰¾è®¾å¤‡é“¾æ¥
            device_links = soup.find_all('a', href=re.compile(r'/en/catalogue/.*\.php'))
            
            if device_links:
                detail_url = urljoin(self.base_url, device_links[0].get('href', ''))
                return self._extract_specifications_from_page(detail_url)
            
            return {}
            
        except Exception as e:
            logger.warning(f"è·å–GSMChoiceè§„æ ¼å¤±è´¥: {str(e)}")
            return {}
    
    def _extract_specifications_from_page(self, detail_url):
        """ä»è¯¦æƒ…é¡µæå–è§„æ ¼ä¿¡æ¯"""
        try:
            self._random_delay()
            
            response = self.session.get(detail_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            specifications = {}
            
            # æŸ¥æ‰¾è§„æ ¼è¡¨æ ¼
            spec_table = soup.find('table', class_='PhoneData')
            if spec_table:
                rows = spec_table.find_all('tr')
                for row in rows:
                    th = row.find('th', class_='phoneCategoryName')
                    td = row.find('td', class_='phoneCategoryValue')
                    
                    if th and td:
                        key = th.get_text(strip=True)
                        value = td.get_text(strip=True)
                        
                        if key and value:
                            specifications[key] = value
            
            logger.info(f"âœ… æå–äº† {len(specifications)} ä¸ªè§„æ ¼é¡¹")
            return specifications
            
        except Exception as e:
            logger.warning(f"æå–è§„æ ¼ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def infer_brand_from_model(self, model_code):
        """ä»å‹å·æ¨æ–­å“ç‰Œ"""
        model_lower = model_code.lower()
        
        brand_patterns = {
            'samsung': [r'^sm-', r'galaxy'],
            'motorola': [r'^moto', r'motorola'],
            'zte': [r'^zte'],
            'lg': [r'^lm-'],
            'huawei': [r'^alt-', r'huawei'],
            'xiaomi': [r'^mi ', r'redmi'],
            'oppo': [r'^cph'],
            'vivo': [r'^v\d+'],
            'hisense': [r'hisense'],
            'tecno': [r'tecno'],
            'cubot': [r'kingkong'],
            'ulefone': [r'tank'],
        }
        
        for brand, patterns in brand_patterns.items():
            for pattern in patterns:
                if re.search(pattern, model_lower):
                    return brand.capitalize()
        
        return 'Unknown'
    
    def close(self):
        """å…³é—­è¿æ¥ï¼ˆGSMChoiceä¸»è¦ä½¿ç”¨requestsï¼Œæ— éœ€ç‰¹æ®Šå…³é—­ï¼‰"""
        logger.info("GSMChoiceçˆ¬è™«å·²å…³é—­")